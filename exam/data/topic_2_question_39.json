{
  "question_text": "HOTSPOT<br/> -<br/><br/>You need to recommend a Fabric streaming solution that will use the sources shown in the following table.<br/><br/><img src=\"images/dp-700_topic-2_question-39_html_1.png\"/><br/><br/>The solution must minimize development effort.<br/><br/>What should you include in the recommendation for each source? To answer, select the appropriate options in the answer area.<br/><br/>NOTE: Each correct selection is worth one point.<br/><br/><img src=\"images/dp-700_topic-2_question-39_html_2.png\"/>",
  "question_images": [
    "images/dp-700_topic-2_question-39_question_1.png",
    "images/dp-700_topic-2_question-39_question_2.png"
  ],
  "answers": {},
  "answer_images": {},
  "correct_answer": [],
  "correct_answer_images": [
    "images/dp-700_topic-2_question-39_correct_1.png"
  ],
  "discussion": "| Source      | Data Type                  | Message Size | Recommended Option                      | Justification                                                                |\n| ----------- | -------------------------- | ------------ | --------------------------------------- | ---------------------------------------------------------------------------- |\n| **Source1** | Semi-structured (bigint)   | **10 MB**    | ✅ **Apache Spark Structured Streaming** | Streaming Dataflow can't reliably handle >4 MB; Spark handles large messages |\n| **Source2** | Structured (19 columns)    | **25 MB**    | ✅ **Apache Spark Structured Streaming** | Too large for Streaming Dataflow; Spark is built for this scale              |\n| **Source3** | Unstructured (with images) | **5 MB**     | ✅ **Apache Spark Structured Streaming** | Binary data + medium size → Spark is the only suitable and scalable option   |\n\nEventstream has 1MB max size limitation, streaming dataflow has been retired in Fabric. We just can choose between Apache Spark Structured Streaming and data pileline(normally it will be used for batch loging solution not Fabric streaming solution). I cannot understand if all of 3 sources have to match Apache Spark Structured Streaming. \nI have to make these answers:\nSource 1, semi-structured, contains a bigint column, Apache Spark Structured Streaming can match it if we choose longType. \nSource 2 is hard to make decision because lost details, I tend to choose data pipleline. \nSource 3 has image, we can use copy activity in data pipeline and set file format to Binary.In order to match \"The solution must minimize development effort.\"\n\nStreaming is not exactly same as ETL Copy Activity.\n\nSource1 (semi-structured, bigint column): An eventstream\nSource2 (structured, 19 columns): A streaming dataflow\nSource3 (unstructured with images): Apache Spark Structured Streaming\n\nStreaming Dataflows were officially retired in March 2023. So, this can be excluded.\nMaximum message size: 1 MB per event\nThis applies to custom endpoints and Azure Event Hubs used within Eventstream. So, Eventstream can be excluded.\n1,2, 3 - Apache Spark Structured Streaming as it supports larger payloads and custom processing logic. Also, it is best for unstructured data like images. It provides flexibility and scalability for custom processing, which is needed for binary/image formats.\n\nI assume this question retired. Streaming dataflow retired. Data pipeline is not streaming. Eventstream cannot handle message size above 1MB. The is no option to choose anything with less development effort than Apache Spark Structured Streaming for all three.\n\nComo o objetivo é minimizar o esforço de desenvolvimento, a melhor escolha costuma ser:\n✅ A streaming dataflow – quando streaming é necessário mas com pouco código.\n❌ Apache Spark Structured Streaming – mais código.\n❌ An eventstream – requer integração adicional.\n❌ A data pipeline – bom para batch, não para streaming.\n\nMy selection:\n- An eventstream\n- A streaming dataflow\n- Apache Spark Structured Streaming\n\nSource1: An eventstream\n\nSource2: A streaming dataflow\n\nSource3: Apache Spark Structured Streaming\n\nConfirmed with Chatgpt\n\nSource1   Apache Spark Structured Streaming \nSource2   An eventstream                    \nSource3   Apache Spark Structured Streaming\n\nThis is such a tricky question. Usually, data from streaming source is not so big. If data size is smaller than 1MB => event stream however data size > 1 MB => Apache Spark structured streaming. Data pipeline doesn't support streaming.\n\nIndeed very tricky,\nIn my for all it will be Spark Structured Streaming\n\neventstream has a message limit of 1 MB. Data pipeline  for batch processing,  streaming dataflow is retired. should be Spark Structured Streaming for all.\n\nstreaming dataflow is not retired\n\nEventstream: Max message size 1 MB \nhttps://learn.microsoft.com/en-us/fabric/real-time-intelligence/event-streams/overview?tabs=enhancedcapabilities#limitations\n\nStreaming Dataflows: \n[Data Types] \n- DateTime: Date and time field in ISO format\n- Float: Decimal number\n- Int: Integer number\n- Record: Nested object with multiple records\n- String: Text\nhttps://learn.microsoft.com/en-us/power-bi/transform-model/dataflows/dataflows-streaming?utm_source=chatgpt.com#data-types\n\n1. **Source1 (Semi-structured data, 10 MB)**:  \n   - **Solution**: **Eventstream**  \n     - Eventstream is optimized for handling semi-structured data and can efficiently process messages with a `bigint` column, while providing real-time streaming capabilities.\n\n2. **Source2 (Structured data, 25 MB)**:  \n   - **Solution**: **Stream Dataflow**  \n     - Stream Dataflow is an appropriate choice for structured data. It allows easy ingestion and transformation of structured datasets, minimizing development effort.\n\n3. **Source3 (Unstructured data with images, 5 MB)**:  \n   - **Solution**: **Spark Structured Streaming**  \n     - Spark Structured Streaming is ideal for processing unstructured data, such as images, in real-time. It provides flexibility for working with diverse data formats.\n\nSource1: cannot be Data pipeline as it is designed for batch processing\nSource2: I need to change it to Spark streaming Structure as Stream dataflow is retired in Fabric\nSource 3:: cannot be Eventstream as it is not designed to handle unstructured data like images or multimedia\n\nSource1- Event Stream (Stream Solution+ Semi Structured file handling)\nSource2: Spark Structured Streaming (Stream Solution + structured file Handling)\nSource3: Spark Structured Streaming (Stream Solution + ustructured file Handling)\nCannot: Data pipeline, as it is only for batch processing, not optimized for Stream\nCannot: Stream dataflow, as it is retired in Fabric\n\nI think both Apache Spark Structured Streaming and data pipeline(if we think it can play role of Fabric streaming solution) can match it. Howerver, question said \"The solution must minimize development effort\", data pipeline is better? \nSource2 didn't give enough details, if this structured data is database and configured with CDC, then eventstream is option. Source 3 should be data pipeline.",
  "question_type": "image_only",
  "exam": "dp-700",
  "topic": 2,
  "question_number": 39,
  "url": "https://www.examtopics.com/discussions/microsoft/view/302502-exam-dp-700-topic-2-question-39-discussion/"
}