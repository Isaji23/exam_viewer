{
  "question_text": "You have a Fabric workspace.<br/>You have semi-structured data.<br/>You need to read the data by using T-SQL, KQL, and Apache Spark. The data will only be written by using Spark.<br/>What should you use to store the data?",
  "question_images": [],
  "answers": {
    "A": "a lakehouse",
    "B": "an eventhouse",
    "C": "a datamart",
    "D": "a warehouse"
  },
  "answer_images": {},
  "correct_answer": [
    "A"
  ],
  "correct_answer_images": [],
  "discussion": "KQL is avaialble in eventhouse only https://learn.microsoft.com/en-us/fabric/fundamentals/decision-guide-data-store\n\nA is still correct because it say's \"Read\"\n\nI think both A and B could be a correct answer for this. \nIf my data is in an eventhouse, I can query it using T-SQL, KQL and PySpark\nIf my data is in a Laekehouse, I can query it using SQL and PySpark and Create shortcuts for it in the eventhouse then query it using KQL. I guess this question needs some other precision to only one possible correct answer\n\nEventhouse:\nRead operations: KQL, Spark and T-SQL\nWrite operations: KQL, Spark\n\nhttps://learn.microsoft.com/en-us/fabric/get-started/decision-guide-data-store\n\nA lakehouse in Microsoft Fabric is the best choice because it supports working with data across multiple analytical engines. CertsMatrix helped me. It allows you to read semi-structured data using T-SQL, KQL, and Apache Spark, which aligns with the requirements. Additionally, a lakehouse fully supports writing data with Spark, making it ideal for scenarios where Spark is the primary write engine. Other options such as eventhouse, datamart, or warehouse do not provide the same level of multi-engine compatibility or flexibility for semi-structured data workloads.\n\nA lakehouse allows you to store semi-structured data in open formats, write using Spark, and read using T-SQL (through the SQL analytics endpoint), KQL (through KQL database shortcuts), and Apache Spark. It is specifically designed for these multi-engine scenarios.\nWhile eventhouse does support reading with KQL and some T-SQL, it is not designed for writing or reading with Apache Spark.\n\nWritten only with spark \nReadable via T-SQL, KQL, and spark\nSemi structured data\n\nAnswer is A:\nWe should consider the fact that it is a semi structured data and not the real time data. We use Eventhouse when we have a streaming/real time data. So for Semi-Structured data, we will store it in a lakehouse and create a short for it in eventhouse. In this way, we can read the data stored in lakehouse using KQL.https://learn.microsoft.com/en-us/fabric/fundamentals/decision-guide-data-store (Here it is clearly mentioned that if you want to store the semi structure data, use Lakehouse and for streaming data, use eventhouse)\n\nA Lakehouse provides the flexibility to write with Spark and query with T-SQL, KQL, and Spark, making it the best fit for your scenario.\n\nEventhouse in Microsoft Fabric is not designed to be written to directly from Apache Spark.\n\nIt is optimized for ingesting real-time and high-velocity telemetry data, typically using Kusto Ingest mechanisms or built-in connectors (like Azure Event Hubs, IoT Hub, etc.).\n\nKQL need Eventhouse\n\nLakehouse:\n- Lakehouse supports reading with T-SQL, KQL, and Apache Spark.\n- Allows writing with Spark.\n- Optimized for semi-structured data like JSON, Parquet, etc.\n- It exposes data via SQL and KQL endpoints and supports Spark access.\nAn eventhouse\n- Designed for real-time event streaming.\nDatamart\n- Only supports T-SQL.\n- Not compatible with Spark or KQL.\n- Not suitable for semi-structured data.\nDatawarehouse\n- Designed for structured data and T-SQL.\n- Does not support Spark or KQL.\n- Not suitable for semi-structured data.\n\neventhouse is optimized for streaming/event data, mainly used with KQL, not suitable for Spark write or T-SQL.\n\nA. a lakehouse ✅\nBuilt on Delta Lake format.\nCan be accessed with T-SQL, KQL, and Spark in Fabric.\nPerfect for semi-structured + multi-engine scenarios.\nB. an eventhouse ❌\nPurpose: real-time analytics with event streams.\nNot designed for semi-structured data with Spark + T-SQL + KQL.\n\nKQL is avaialble in eventhouse only https://learn.microsoft.com/en-us/fabric/fundamentals/decision-guide-data-store\n\nEventhouse is optimized for real-time event data. While it supports both KQL and Apache Spark, it is not designed for Spark-centric scenarios involving semi-structured data written exclusively using Spark.\n\nThe eventhouse is not designed for semi-structured data, it is designed for columnar data such as log, you can use event stream and KQL pipeline to write data into eventhouse, but you cannot directly use Spark to write data into eventhouse.\nIn a Lakehouse, you can create a shortcut to its underlying Delta tables, enabling KQL to query the data directly through that shortcut.\n\nLakehouse in Microsoft Fabric is designed to store semi-structured and unstructured data in an open format (Delta/Parquet). It supports being read by T-SQL, KQL, and Apache Spark in the same workspace. You can write data using Spark and still query it from SQL endpoints or KQL without extra ingestion steps.\n\nFor Fabric, storage account is lakehouse.",
  "question_type": "multiple_choice",
  "exam": "dp-700",
  "topic": 1,
  "question_number": 2,
  "url": "https://www.examtopics.com/discussions/microsoft/view/152626-exam-dp-700-topic-1-question-2-discussion/"
}