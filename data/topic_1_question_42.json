{
  "question_text": "DRAG DROP<br/> -<br/><br/>You have two Fabric notebooks named Load_Salesperson and Load_Orders that read data from Parquet files in a lakehouse. Load_Salesperson writes to a Delta table named dim_salesperson. Load_Orders writes to a Delta table named fact_orders and is dependent on the successful execution of Load_Salesperson.<br/><br/>You need to implement a pattern to dynamically execute Load_Salesperson and Load_Orders in the appropriate order by using a notebook.<br/><br/>How should you complete the code? To answer, drag the appropriate values the correct targets. Each value may be used once, more than once, or not at all. You may need to drag the split bar between panes or scroll to view content.<br/><br/>NOTE: Each correct selection is worth one point.<br/><br/><img src=\"https://img.examtopics.com/dp-700/image66.png\"/>",
  "question_images": [
    "https://img.examtopics.com/dp-700/image66.png"
  ],
  "answers": {},
  "answer_images": {},
  "correct_answer": [],
  "correct_answer_images": [
    "https://img.examtopics.com/dp-700/image67.png"
  ],
  "discussion": "Correct\nactivities: to list the activities\ndependencies: to make sure the order and dependency of running\nrunMultiple: there are 2 notebooks to be executed\n\nAgree. https://learn.microsoft.com/en-us/fabric/data-engineering/microsoft-spark-utilities#reference-run-multiple-notebooks-in-parallel\n\nAlthough nothing will run in parallel here because of the dependency, the code is correct.\n\nactivities:\n‚ùå This is not a valid key for mssparkutils.notebook.runMultiple(). If you use \"activities\" instead of \"runMultiple\", the function will not recognize the execution plan and will fail.\n\n-activities\n-dependencies\n-runMultiple()\nExecutes notebooks based on a DAG (Directed Acyclic Graph) structure.\nSupports sequential and parallel execution.\nAllows defining dependencies between notebooks.\n\nDAG = {\n  \"activities\": [\n    {\"name\": \"step1\", \"path\": \"Notebook1\"},\n    {\"name\": \"step2\", \"path\": \"Notebook2\", \"dependencies\": [\"step1\"]}\n  ],\n  \"timeoutInSeconds\": 3600,\n  \"concurrency\": 2\n}\n\nmssparkutils.notebook.runMultiple(DAG)\nhttps://fabric.guru/using-runmultiple-to-orchastrate-notebook-execution-in-microsoft-fabric\n\nThe answer is correct:\nactivities\ndependencies\nrunMultiple\n\nDAG = {\n    \"runMultiple\": [\n        {\n            \"name\": \"Load_Salesperson\",\n            \"path\": \"Load_Salesperson\",\n            \"timeoutPerCellInSeconds\": 300,\n        },\n        {\n            \"name\": \"Load_Orders\",\n            \"path\": \"Load_Orders\",\n            \"timeoutPerCellInSeconds\": 600,\n            \"dependencies\": [\"Load_Salesperson\"]\n        }\n    ],\n    \"timeoutInSeconds\": 43200\n}\n\nmssparkutils.notebook.runMultiple(DAG)\n\nNo, take a look here https://learn.microsoft.com/en-us/fabric/data-engineering/microsoft-spark-utilities#reference-run-multiple-notebooks-in-parallel\n\nThe requirement:\nexecute Load_Salesperson and Load_Orders in the appropriate order\nHow is it related with \"run-multiple-notebooks-in-parallel\"?\n\nI'm not sure about Notebook or Activity. In Fabric Pipeline use Activity and type Notebook. Others ok\n\nhttps://learn.microsoft.com/en-us/fabric/data-engineering/microsoft-spark-utilities#reference-run-multiple-notebooks-in-parallel\n\nThe requirement:\nexecute Load_Salesperson and Load_Orders in the appropriate order\nHow is it related with \"run-multiple-notebooks-in-parallel\"?\n\nCorrect answer should be:\n\n\"notebooks\" defines the list of notebook execution steps.\n\n\"dependencies\" specifies that Load_Orders depends on Load_Salesperson.\n\nmssparkutils.notebook.runMultiple() is the correct API call to execute a DAG of notebooks in Fabric.\n\nIn Azure Data Factory and Synapse Pipelines, workflows use activities ...not in Fabric",
  "question_type": "drag_drop",
  "source": "direct_html",
  "url": "https://www.examtopics.com/discussions/microsoft/view/302431-exam-dp-700-topic-1-question-42-discussion/",
  "topic": 1,
  "question_number": 42
}